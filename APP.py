# Authorï¼šTkun
# createTimeï¼š2025/8/15
# FileNameï¼šAPP
# Descriptionï¼šsimple introduction of the code
# app.py
# å¯¼å…¥å¿…è¦çš„åº“
#pip install streamlit
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    roc_auc_score,
    classification_report,
    roc_curve
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
import xgboost as xgb
import lightgbm as lgb
import joblib
import os
import warnings
import shap
from io import BytesIO

# --- é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(
    page_title="å¤šæ¨¡å‹æ™ºèƒ½æ—å‹åˆ†ç±»å™¨",
    page_icon="ğŸŒ³",
    layout="wide"
)

# --- ç¯å¢ƒä¸ç»˜å›¾è®¾ç½® ---
# Streamlit ä¼šå¤„ç† matplotlib çš„åç«¯ï¼Œé€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½® 'Agg'
# matplotlib.use('Agg')
# --- ç¯å¢ƒä¸ç»˜å›¾è®¾ç½® ---
try:
    # æ­¥éª¤1ï¼šå°è¯•æ‰§è¡Œè¿™é‡Œçš„ä»£ç 
    # æˆ‘ä»¬ä¹è§‚åœ°è®¤ä¸ºç³»ç»Ÿä¸­æœ‰ 'Microsoft YaHei' å­—ä½“
    plt.rcParams['font.family'] = 'Microsoft YaHei'
    print("å­—ä½“æˆåŠŸè®¾ç½®ä¸º 'Microsoft YaHei'") # è¿™è¡Œæ˜¯å¯é€‰çš„ï¼Œç”¨äºè°ƒè¯•
except Exception as e:
    # æ­¥éª¤2ï¼šå¦‚æœ 'try' å—ä¸­çš„ä»£ç æ‰§è¡Œå¤±è´¥ï¼ˆæŠ›å‡ºå¼‚å¸¸ï¼‰ï¼Œåˆ™ç«‹å³è·³è½¬åˆ°è¿™é‡Œæ‰§è¡Œ
    # è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿåœ¨ Linux æœåŠ¡å™¨ç­‰æ²¡æœ‰é¢„è£… Windows å­—ä½“çš„åœ°æ–¹
    print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ° 'Microsoft YaHei' å­—ä½“ï¼Œé”™è¯¯ä¿¡æ¯: {e}ã€‚æ­£åœ¨å›é€€åˆ°å¤‡ç”¨å­—ä½“...")
    # æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªåœ¨ Linux ç³»ç»Ÿä¸Šæ›´å¸¸è§çš„å¤‡ç”¨ä¸­æ–‡å­—ä½“'SimHei'ï¼ˆé»‘ä½“ï¼‰
    # 'sans-serif'æ˜¯æœ€åçš„å¤‡é€‰é¡¹ï¼Œå®ƒä¼šä½¿ç”¨ç³»ç»Ÿé»˜è®¤çš„æ— è¡¬çº¿å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'sans-serif']

# è¿™ä¸€è¡Œä»£ç æ— è®ºå­—ä½“è®¾ç½®æˆåŠŸä¸å¦éƒ½åº”è¯¥æ‰§è¡Œï¼Œæ‰€ä»¥æ”¾åœ¨ try-except å—çš„å¤–é¢
# å®ƒçš„ä½œç”¨æ˜¯ç¡®ä¿å›¾è¡¨ä¸­çš„è´Ÿå·'-'èƒ½æ­£å¸¸æ˜¾ç¤º
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

# ä½¿ç”¨ Streamlit ç¼“å­˜æ¥åŠ è½½å’Œé¢„å¤„ç†æ•°æ®ï¼Œé¿å…é‡å¤è¯»å–
@st.cache_data
def load_and_process_data(uploaded_file):
    """åŠ è½½æ•°æ®ã€åˆ’åˆ†æ•°æ®é›†å¹¶è¿›è¡Œæ ‡å‡†åŒ–"""
    df = pd.read_excel(uploaded_file)

    y = df.iloc[:, 1]
    x_df = df.iloc[:, 2:]
    feature_names = x_df.columns.tolist()
    class_names = [
        'è½å¶é˜”å¶æ—', 'å¸¸ç»¿é˜”å¶æ—', 'é’ˆé˜”æ··äº¤æ—', 'å¸¸ç»¿é’ˆå¶æ—',
        'è½å¶é’ˆå¶æ—', 'ç«¹æ—', 'çŒæœ¨æ—', 'ç»æµæ—'
    ]
    num_classes = len(np.unique(y))

    if len(class_names) != num_classes:
        st.error(f"æŒ‡å®šçš„ç±»åˆ«åç§°æ•°é‡ ({len(class_names)}) ä¸æ•°æ®ä¸­çš„ç±»åˆ«æ•°é‡ ({num_classes}) ä¸åŒ¹é…ã€‚")
        return None

    x_train_df, x_test_df, y_train, y_test = train_test_split(x_df, y, test_size=0.3, random_state=42, stratify=y)

    scaler = StandardScaler()
    X_train_scaled_df = pd.DataFrame(scaler.fit_transform(x_train_df), columns=feature_names)
    X_test_scaled_df = pd.DataFrame(scaler.transform(x_test_df), columns=feature_names)

    return X_train_scaled_df, X_test_scaled_df, y_train, y_test, feature_names, class_names, num_classes


# ä½¿ç”¨ç¼“å­˜æ¥è®­ç»ƒæ¨¡å‹ï¼Œåªæœ‰åœ¨æ•°æ®å˜åŒ–æ—¶æ‰é‡æ–°è®­ç»ƒï¼Œæå¤§æå‡ä½“éªŒ
@st.cache_data
def train_and_evaluate_models(_X_train, _y_train, _X_test, _y_test, class_names, num_classes):
    """è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶è¯„ä¼°æ€§èƒ½"""
    models = {
        'XGBoost': xgb.XGBClassifier(random_state=42, objective='multi:softprob', num_class=num_classes,
                                     eval_metric='mlogloss', use_label_encoder=False),
        'LightGBM': lgb.LGBMClassifier(random_state=42),
        'RandomForest': RandomForestClassifier(random_state=42),
        'DecisionTree': DecisionTreeClassifier(random_state=42),
        'LogisticRegression': LogisticRegression(random_state=42, multi_class='ovr', max_iter=1000),
        'KNN': KNeighborsClassifier(),
        'SVM': SVC(random_state=42, probability=True)
    }

    results = {}

    progress_bar = st.progress(0)
    total_models = len(models)

    for i, (model_name, model) in enumerate(models.items()):
        model.fit(_X_train, _y_train)
        y_pred_proba = model.predict_proba(_X_test)
        y_pred_class = model.predict(_X_test)

        accuracy = classification_report(_y_test, y_pred_class, target_names=class_names, output_dict=True)['accuracy']
        weighted_roc_auc = roc_auc_score(_y_test, y_pred_proba, multi_class='ovr', average='weighted')

        results[model_name] = {
            'model': model,
            'y_pred_proba': y_pred_proba,
            'accuracy': accuracy,
            'weighted_roc_auc': weighted_roc_auc
        }
        progress_bar.progress((i + 1) / total_models, text=f"æ­£åœ¨è®­ç»ƒæ¨¡å‹: {model_name}...")

    progress_bar.empty()  # å®Œæˆåéšè—è¿›åº¦æ¡
    return results


def plot_multimodel_roc_comparison(results, y_true, class_names):
    """ç»˜åˆ¶å¤šæ¨¡å‹ROCæ€§èƒ½æ¯”è¾ƒå›¾"""
    fig, ax = plt.subplots(figsize=(12, 9))
    mean_fpr = np.linspace(0, 1, 100)

    for model_name, result in results.items():
        y_proba = result['y_pred_proba']
        all_tpr = []
        # æ³¨æ„ y_true æ˜¯ä» 1 å¼€å§‹çš„ï¼Œéœ€è¦è½¬æ¢ä¸º 0-indexed
        y_true_0_indexed = y_true - 1
        for i in range(len(class_names)):
            fpr, tpr, _ = roc_curve((y_true_0_indexed == i).astype(int), y_proba[:, i])
            tpr = np.interp(mean_fpr, fpr, tpr)
            tpr[0] = 0.0
            all_tpr.append(tpr)
        mean_tpr = np.mean(all_tpr, axis=0)
        mean_tpr[-1] = 1.0
        mean_auc = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')
        ax.plot(mean_fpr, mean_tpr, label=f'{model_name} (å®å¹³å‡AUC = {mean_auc:.3f})')

    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('å‡æ­£ç‡', fontsize=14)
    ax.set_ylabel('çœŸæ­£ç‡', fontsize=14)
    ax.set_title('å¤šæ¨¡å‹ROCæ€§èƒ½æ¯”è¾ƒ (å®å¹³å‡)', fontsize=18)
    ax.legend(loc="lower right", fontsize=12)
    ax.grid(True)
    return fig


def perform_shap_analysis(model, model_name, X_train, X_test, feature_names, class_names):
    """å¯¹æœ€ä½³æ¨¡å‹è¿›è¡ŒSHAPåˆ†æå¹¶è¿”å›å›¾åƒ"""
    st.write(f"æ­£åœ¨ä¸ºæœ€ä½³æ¨¡å‹ [{model_name}] è®¡ç®— SHAP å€¼ï¼Œè¯·ç¨å€™...")

    N_SHAP_SAMPLES = 50
    if len(X_test) > N_SHAP_SAMPLES:
        X_test_shap = X_test.sample(N_SHAP_SAMPLES, random_state=42)
    else:
        X_test_shap = X_test

    tree_based_models = ['XGBoost', 'LightGBM', 'RandomForest', 'DecisionTree']

    if model_name in tree_based_models:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(X_test_shap)
    else:
        # KernelExplainerå¾ˆæ…¢ï¼Œç»™ç”¨æˆ·ä¸€ä¸ªæç¤º
        with st.spinner(f'æ­£åœ¨ä½¿ç”¨ KernelExplainer è®¡ç®— {model_name} çš„ SHAP å€¼ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...'):
            background_data = shap.kmeans(X_train, 50)
            explainer = shap.KernelExplainer(model.predict_proba, background_data)
            shap_values = explainer.shap_values(X_test_shap)

    # ç»˜åˆ¶ SHAP summary plot
    fig, ax = plt.subplots()
    shap.summary_plot(shap_values, X_test_shap, feature_names=feature_names, class_names=class_names, show=False,
                      plot_type='bar')
    plt.title(f'{model_name} ç»¼åˆç‰¹å¾é‡è¦æ€§æ’åº', fontsize=16)
    # æ‰‹åŠ¨è°ƒæ•´å¸ƒå±€ä»¥é˜²æ­¢æ ‡ç­¾è¢«æˆªæ–­
    plt.tight_layout()
    return fig


# --- Streamlit UI ç•Œé¢ ---
st.title("ğŸŒ³ å¤šæ¨¡å‹æ™ºèƒ½æ—å‹åˆ†ç±»ä¸å¯è§£é‡Šæ€§åˆ†æå¹³å°")
st.markdown("""
æ¬¢è¿ä½¿ç”¨æœ¬å¹³å°ï¼è¯·ä¸Šä¼ æ‚¨çš„æ—å‹æ•°æ®ï¼ˆExcelæ ¼å¼ï¼‰ï¼Œå¹³å°å°†è‡ªåŠ¨å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1.  **æ•°æ®å¤„ç†**ï¼šåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶è¿›è¡Œæ ‡å‡†åŒ–ã€‚
2.  **å¤šæ¨¡å‹è®­ç»ƒ**ï¼šä½¿ç”¨ä¸ƒç§ä¸»æµåˆ†ç±»æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚
3.  **æ€§èƒ½è¯„ä¼°**ï¼šæ¯”è¾ƒå„æ¨¡å‹çš„å‡†ç¡®ç‡å’ŒAUCï¼Œå¹¶å¯è§†åŒ–ROCæ›²çº¿ã€‚
4.  **æ¨¡å‹ä¼˜é€‰**ï¼šè‡ªåŠ¨é€‰å‡ºè¡¨ç°æœ€ä½³çš„æ¨¡å‹ã€‚
5.  **å¯è§£é‡Šæ€§åˆ†æ**ï¼šåˆ©ç”¨SHAPå¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œç‰¹å¾é‡è¦æ€§åˆ†æã€‚
""")

# --- ä¾§è¾¹æ ï¼šç”¨æˆ·è¾“å…¥ ---
with st.sidebar:
    st.header("âš™ï¸ æ“ä½œé¢æ¿")
    uploaded_file = st.file_uploader("ä¸Šä¼ æ‚¨çš„Excelæ•°æ®æ–‡ä»¶", type=["xlsx"])

    # ä½¿ç”¨é»˜è®¤æ•°æ®ä½œä¸ºç¤ºä¾‹
    use_default_data = st.checkbox("ä½¿ç”¨å†…ç½®ç¤ºä¾‹æ•°æ®", value=True)

    analyze_button = st.button("ğŸš€ å¼€å§‹åˆ†æ")

# --- ä¸»é¡µé¢ï¼šç»“æœå±•ç¤º ---
if analyze_button:
    if uploaded_file is not None or use_default_data:
        if use_default_data:
            # å¦‚æœç”¨æˆ·é€‰æ‹©ä½¿ç”¨é»˜è®¤æ•°æ®ï¼Œæˆ‘ä»¬ä»æœ¬åœ°åŠ è½½
            try:
                default_file_path = 'æ—å‹åˆ†ç±»æ•°æ®.xlsx'
                uploaded_file = open(default_file_path, 'rb')
                st.info("æ­£åœ¨ä½¿ç”¨å†…ç½®ç¤ºä¾‹æ•°æ®...")
            except FileNotFoundError:
                st.error("é”™è¯¯ï¼šæœªæ‰¾åˆ°é»˜è®¤æ•°æ®æ–‡ä»¶ 'æ—å‹åˆ†ç±»æ•°æ®.xlsx'ã€‚è¯·å–æ¶ˆå‹¾é€‰æˆ–å°†æ–‡ä»¶æ”¾ç½®åœ¨åº”ç”¨æ ¹ç›®å½•ã€‚")
                st.stop()

        # 1. æ•°æ®å‡†å¤‡
        st.header("1. æ•°æ®å‡†å¤‡ä¸å¤„ç†")
        with st.spinner('æ­£åœ¨åŠ è½½å’Œå¤„ç†æ•°æ®...'):
            data_load_state = st.text('åŠ è½½æ•°æ®ä¸­...')
            processed_data = load_and_process_data(uploaded_file)
            data_load_state.text('æ•°æ®åŠ è½½å’Œå¤„ç†å®Œæˆï¼')

        if processed_data:
            X_train, X_test, y_train, y_test, feature_names, class_names, num_classes = processed_data
            st.success("æ•°æ®å·²æˆåŠŸåˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶å®Œæˆæ ‡å‡†åŒ–ã€‚")
            st.write(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(X_train)}, æµ‹è¯•é›†æ ·æœ¬æ•°: {len(X_test)}")

        # 2. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°
        st.header("2. æ¨¡å‹è®­ç»ƒä¸æ¯”è¾ƒ")
        with st.spinner('æ­£åœ¨è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...'):
            results = train_and_evaluate_models(X_train, y_train, X_test, y_test, class_names, num_classes)

        st.success("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

        # å°†ç»“æœæ•´ç†æˆDataFrameå±•ç¤º
        results_df = pd.DataFrame({
            'æ¨¡å‹': list(results.keys()),
            'å‡†ç¡®ç‡ (Accuracy)': [res['accuracy'] for res in results.values()],
            'åŠ æƒROC AUC': [res['weighted_roc_auc'] for res in results.values()]
        }).sort_values(by='åŠ æƒROC AUC', ascending=False).reset_index(drop=True)

        st.dataframe(results_df)

        # 3. æ€§èƒ½å¯è§†åŒ–
        st.header("3. æ¨¡å‹æ€§èƒ½å¯è§†åŒ–")
        with st.spinner('æ­£åœ¨ç”ŸæˆROCå¯¹æ¯”å›¾...'):
            roc_fig = plot_multimodel_roc_comparison(results, y_test, class_names)
            st.pyplot(roc_fig)

        # 4. æœ€ä½³æ¨¡å‹é€‰æ‹©ä¸ä¸‹è½½
        st.header("4. æœ€ä½³æ¨¡å‹é€‰æ‹©ä¸å¯è§£é‡Šæ€§åˆ†æ")
        best_model_name = max(results, key=lambda name: results[name]['weighted_roc_auc'])
        best_model = results[best_model_name]['model']

        st.info(f"**æœ€ä½³æ¨¡å‹æ˜¯: {best_model_name}** (åŠ æƒROC AUC: {results[best_model_name]['weighted_roc_auc']:.4f})")

        # å°†æ¨¡å‹ä¿å­˜åˆ°å†…å­˜ä¸­ï¼Œä»¥ä¾¿ç”¨æˆ·ä¸‹è½½
        model_buffer = BytesIO()
        joblib.dump(best_model, model_buffer)
        model_buffer.seek(0)

        st.download_button(
            label=f"ğŸ“¥ ä¸‹è½½æœ€ä½³æ¨¡å‹ ({best_model_name}.joblib)",
            data=model_buffer,
            file_name=f'Best_Model_{best_model_name}.joblib',
            mime='application/octet-stream'
        )

        # 5. SHAPåˆ†æ
        with st.spinner(f'æ­£åœ¨ä¸ºæœ€ä½³æ¨¡å‹ [{best_model_name}] è¿›è¡ŒSHAPåˆ†æ...'):
            shap_fig = perform_shap_analysis(best_model, best_model_name, X_train, X_test, feature_names, class_names)
            st.pyplot(shap_fig)

        st.balloons()
        st.success("æ‰€æœ‰åˆ†æå®Œæˆï¼")

    else:
        st.warning("è¯·ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶æˆ–é€‰æ‹©ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼Œç„¶åç‚¹å‡»'å¼€å§‹åˆ†æ'æŒ‰é’®ã€‚")